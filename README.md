# Tactical Decision Making Strategy for Autonomous Driving using Deep Reinforcement Learning Techniques

## Course: CMPE 297 sec 47 Reinforcement Learning

## Team Members

Team Members | Contributions | 
--- | --- |
Sivaranjani Kumar |  Setting up the highway environment for autonomous driving, Creating configuration files for driving environment, Running simulations for highway driving, Ablation study, Model training - Deep-Q Network algorithm, Optimizing and testing the DQN agent to make optimal decisions.    |
Vigneshkumar Thangarajan |  Requirement and dependency identification for DDQN based RL agent, Model Training - DDQN with Dueling architecture algorithm, Hyperparameter Tuning, Creating comparisons for two models, Optimizing and testing the DDQN agent with dueling architecture to make optimal decisions.    |

## Project Summary

The high-level decision-making strategies for autonomous driving have seen less progress compared to other areas. Itâ€™s because only few use cases are addressed and most of them cannot scale to more complex scenes, when decision-making involves interacting with other human drivers, whose behaviors are uncertain and difficult to model explicitly.  The cost involved in collecting human driving data is very expensive and not possible to record all the possible driving scenarios. The promising approach to achieve this without much hassle is to train a decision-making policy using reinforcement learning. RL leverages driving agent to automatically learn a complex driving policy to imitate the human driving decisions. The goal of our project is to train an autonomous driving agent to drive efficiently by following the safe maneuvers to overtake other driving vehicles in a simulated highway environment. To achieve this, we have implemented two DRL techniques, DQN and DDQN with Dueling Network Architecture which will increase the efficiency of driving agent in a highway environment. 

## Highway Environment

The highway environment consists of multiple lanes where the ego vehicle which is a driving agent and other surrounding vehicles can drive.  The agent is driving on a straight highway with several lanes, and is rewarded for reaching a high speed, staying on the rightmost lanes and avoiding collisions. The reward points for the agent are specified in the config file. 

RIGHT_LANE_REWARD: float= 0.1 
HIGH_SPEED_REWARD: float= 0.4 
LANE_CHANGE_REWARD: float= 0 
COLLISION_REWARD: -1 
CONTROLLED_VEHICLE: 1 

![alt text](https://github.com/RL-AutonomousDriving/RL_algorithm/blob/main/Images/Highway.png)

## Hierarchical Motion Controller:

To manage the lateral and longitudinal movements of the ego and surrounding vehicles. It consists of two parts. The upper level contains two models, which are Intelligent driver model (IDM) and Minimize overall braking induced by lane changes (MOBIL). The lower level focuses on regulating vehicle velocity and acceleration. The original speed of the ego vehicle is chosen from [23, 25] m/s and the maximum speed of vehicle is 40 m/s. The length and width of all vehicles are 5m and 2m. The initial velocity of the surrounding vehicles is randomly chosen from [20, 23] m/s, and their behaviors are manipulated by IDM and MOBIL. Car-following and collision free is handled by IDM and it is implemented for Adaptive Cruise Controller (ACC). 

![alt text](https://github.com/RL-AutonomousDriving/RL_algorithm/blob/main/Images/env.png)




